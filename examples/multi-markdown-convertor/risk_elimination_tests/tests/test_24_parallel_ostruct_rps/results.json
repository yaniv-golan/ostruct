{
  "test_id": "24",
  "test_name": "Parallel ostruct calls saturate RPS limit safely",
  "num_parallel_calls": 20,
  "template_created": true,
  "schema_created": true,
  "calls_completed": 20,
  "calls_successful": 20,
  "calls_rate_limited": 0,
  "calls_with_errors": 0,
  "total_duration": 1.6059741973876953,
  "average_call_duration": 1.5582001090049744,
  "max_call_duration": 1.5929758548736572,
  "min_call_duration": 1.5000481605529785,
  "call_details": [
    {
      "call_id": 6,
      "start_time": 1749289080.73404,
      "success": true,
      "return_code": 0,
      "duration": 1.5055701732635498,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 6\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 6\n\n"
    },
    {
      "call_id": 19,
      "start_time": 1749289080.762656,
      "success": true,
      "return_code": 0,
      "duration": 1.5000481605529785,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 19\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 19\n\n"
    },
    {
      "call_id": 15,
      "start_time": 1749289080.750417,
      "success": true,
      "return_code": 0,
      "duration": 1.520960807800293,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 15\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 15\n\n"
    },
    {
      "call_id": 14,
      "start_time": 1749289080.746442,
      "success": true,
      "return_code": 0,
      "duration": 1.5352990627288818,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 14\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 14\n\n"
    },
    {
      "call_id": 18,
      "start_time": 1749289080.7618182,
      "success": true,
      "return_code": 0,
      "duration": 1.5244417190551758,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 18\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 18\n\n"
    },
    {
      "call_id": 20,
      "start_time": 1749289080.773715,
      "success": true,
      "return_code": 0,
      "duration": 1.5139050483703613,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 20\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 20\n\n"
    },
    {
      "call_id": 2,
      "start_time": 1749289080.73193,
      "success": true,
      "return_code": 0,
      "duration": 1.5624878406524658,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 2\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 2\n\n"
    },
    {
      "call_id": 12,
      "start_time": 1749289080.741896,
      "success": true,
      "return_code": 0,
      "duration": 1.556520938873291,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 12\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 12\n\n"
    },
    {
      "call_id": 9,
      "start_time": 1749289080.73768,
      "success": true,
      "return_code": 0,
      "duration": 1.5636861324310303,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 9\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 9\n\n"
    },
    {
      "call_id": 5,
      "start_time": 1749289080.732492,
      "success": true,
      "return_code": 0,
      "duration": 1.5710229873657227,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 5\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 5\n\n"
    },
    {
      "call_id": 7,
      "start_time": 1749289080.736557,
      "success": true,
      "return_code": 0,
      "duration": 1.575287103652954,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 7\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 7\n\n"
    },
    {
      "call_id": 1,
      "start_time": 1749289080.7305741,
      "success": true,
      "return_code": 0,
      "duration": 1.5815119743347168,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 1\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 1\n\n"
    },
    {
      "call_id": 10,
      "start_time": 1749289080.740416,
      "success": true,
      "return_code": 0,
      "duration": 1.5745959281921387,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 10\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 10\n\n"
    },
    {
      "call_id": 8,
      "start_time": 1749289080.7368262,
      "success": true,
      "return_code": 0,
      "duration": 1.5792148113250732,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 8\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 8\n\n"
    },
    {
      "call_id": 3,
      "start_time": 1749289080.732175,
      "success": true,
      "return_code": 0,
      "duration": 1.5889737606048584,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 3\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 3\n\n"
    },
    {
      "call_id": 16,
      "start_time": 1749289080.754265,
      "success": true,
      "return_code": 0,
      "duration": 1.5670127868652344,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 16\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 16\n\n"
    },
    {
      "call_id": 4,
      "start_time": 1749289080.732425,
      "success": true,
      "return_code": 0,
      "duration": 1.591440200805664,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 122\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 4\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 122 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 4\n\n"
    },
    {
      "call_id": 17,
      "start_time": 1749289080.756376,
      "success": true,
      "return_code": 0,
      "duration": 1.5713589191436768,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 17\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 17\n\n"
    },
    {
      "call_id": 13,
      "start_time": 1749289080.745101,
      "success": true,
      "return_code": 0,
      "duration": 1.5876879692077637,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 13\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 13\n\n"
    },
    {
      "call_id": 11,
      "start_time": 1749289080.741444,
      "success": true,
      "return_code": 0,
      "duration": 1.5929758548736572,
      "error": null,
      "rate_limited": false,
      "api_error": false,
      "stdout": "\ud83d\udcca Token Analysis:\n   \u2022 Input tokens: 123\n   \u2022 Max output tokens: 16,384\n   \u2022 Context window: 128,000\n   \u2022 Estimated cost: $0.1641 (using gpt-4o rates)\n   \u2022 Context utilization: 12.9%\n",
      "stderr": "\ud83d\udd27 Validating configuration...\n\ud83d\udcc2 Processing input files...\nINFO:ostruct.cli.config:No configuration file found, using defaults\n\ud83d\udcdd Rendering template...\nINFO:ostruct:=== Template Context ===\nINFO:ostruct:  prompt: str\nINFO:ostruct:  current_model: str\nINFO:ostruct:  web_search_enabled: bool\nINFO:ostruct:  code_interpreter_enabled: bool\nINFO:ostruct:  auto_download_enabled: bool\nINFO:ostruct:  code_interpreter_config: DotDict\nINFO:ostruct:  stdin: StdinProxy\nINFO:ostruct:Template render result (first 100 chars): '---\\nsystem: You are a helpful assistant.\\n---\\n\\nPlease provide a brief response to: Test call 11\\n'\n\u2705 Validating model and schema...\n\u2705 Validation results:\n  \u251c\u2500\u2500 Schema: \u2705 Valid\n  \u251c\u2500\u2500 Template: \u2705 Valid\n  \u2514\u2500\u2500 Tokens: 123 / 128,000 (0.1%)\n\u2705 Dry run completed successfully - all validations passed\nINFO:ostruct.cli.runner:\nSystem Prompt:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:You are a helpful assistant.\nINFO:ostruct.cli.runner:\nRendered Template:\nINFO:ostruct.cli.runner:----------------------------------------\nINFO:ostruct.cli.runner:---\nsystem: You are a helpful assistant.\n---\n\nPlease provide a brief response to: Test call 11\n\n"
    }
  ],
  "success": true,
  "error": null
}