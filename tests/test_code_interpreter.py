"""Tests for Code Interpreter integration."""

import os
import tempfile
from unittest.mock import AsyncMock, Mock, patch

import pytest
from ostruct.cli.code_interpreter import CodeInterpreterManager


class TestCodeInterpreterManager:
    """Test Code Interpreter management and integration."""

    def setup_method(self):
        """Set up test fixtures."""
        self.mock_client = AsyncMock()
        self.manager = CodeInterpreterManager(self.mock_client)

    def test_manager_initialization(self):
        """Test manager initialization."""
        assert isinstance(self.manager, CodeInterpreterManager)
        assert self.manager.client == self.mock_client
        assert self.manager.uploaded_file_ids == []

    @pytest.mark.asyncio
    async def test_upload_files_for_code_interpreter_success(self):
        """Test successful file upload for Code Interpreter."""
        # Create temporary test files
        with tempfile.TemporaryDirectory() as temp_dir:
            test_file1 = os.path.join(temp_dir, "test1.py")
            test_file2 = os.path.join(temp_dir, "test2.csv")

            with open(test_file1, "w") as f:
                f.write('print("hello world")')
            with open(test_file2, "w") as f:
                f.write("name,value\ntest,123")

            # Mock OpenAI file upload responses
            mock_file1 = Mock()
            mock_file1.id = "file-123456"
            mock_file2 = Mock()
            mock_file2.id = "file-789012"

            self.mock_client.files.create.side_effect = [
                mock_file1,
                mock_file2,
            ]

            # Test upload
            file_ids = await self.manager.upload_files_for_code_interpreter(
                [test_file1, test_file2]
            )

            assert len(file_ids) == 2
            assert file_ids == ["file-123456", "file-789012"]
            assert self.manager.uploaded_file_ids == [
                "file-123456",
                "file-789012",
            ]
            assert self.mock_client.files.create.call_count == 2

            # Verify correct purpose was used
            for call in self.mock_client.files.create.call_args_list:
                assert call[1]["purpose"] == "assistants"

    @pytest.mark.asyncio
    async def test_upload_files_file_not_found(self):
        """Test file upload with non-existent file."""
        non_existent_file = "/path/that/does/not/exist.py"

        with pytest.raises(FileNotFoundError, match="File not found"):
            await self.manager.upload_files_for_code_interpreter(
                [non_existent_file]
            )

    @pytest.mark.asyncio
    async def test_upload_files_upload_failure(self):
        """Test file upload with OpenAI API failure."""
        with tempfile.TemporaryDirectory() as temp_dir:
            test_file = os.path.join(temp_dir, "test.py")
            with open(test_file, "w") as f:
                f.write('print("test")')

            # Mock upload failure
            self.mock_client.files.create.side_effect = Exception("API Error")

            with pytest.raises(Exception, match="API Error"):
                await self.manager.upload_files_for_code_interpreter(
                    [test_file]
                )

    def test_build_tool_config(self):
        """Test building Code Interpreter tool configuration."""
        file_ids = ["file-123", "file-456", "file-789"]

        config = self.manager.build_tool_config(file_ids)

        expected_config = {
            "type": "code_interpreter",
            "container": {"type": "auto", "file_ids": file_ids},
        }

        assert config == expected_config

    def test_build_tool_config_empty_files(self):
        """Test building tool config with no files."""
        config = self.manager.build_tool_config([])

        expected_config = {
            "type": "code_interpreter",
            "container": {"type": "auto", "file_ids": []},
        }

        assert config == expected_config

    @pytest.mark.asyncio
    async def test_download_generated_files_success(self):
        """Test downloading files generated by Code Interpreter."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Mock file info and content
            mock_file_info1 = Mock()
            mock_file_info1.filename = "chart.png"
            mock_file_info2 = Mock()
            mock_file_info2.filename = "results.csv"

            mock_content1 = Mock()
            mock_content1.read.return_value = b"fake image data"
            mock_content2 = Mock()
            mock_content2.read.return_value = b"name,value\ntest,123"

            self.mock_client.files.retrieve.side_effect = [
                mock_file_info1,
                mock_file_info2,
            ]
            self.mock_client.files.content.side_effect = [
                mock_content1,
                mock_content2,
            ]

            # Create mock response with new Responses API structure
            mock_response = Mock()
            mock_response.output = []

            # Create mock message items with annotations
            mock_msg1 = Mock()
            mock_msg1.type = "message"
            mock_msg1.content = [Mock()]
            mock_msg1.content[0].annotations = [Mock()]
            mock_msg1.content[0].annotations[
                0
            ].type = "container_file_citation"
            mock_msg1.content[0].annotations[0].file_id = "file-output-123"
            mock_msg1.content[0].annotations[0].container_id = "container-123"
            mock_msg1.content[0].annotations[0].filename = "chart.png"

            mock_msg2 = Mock()
            mock_msg2.type = "message"
            mock_msg2.content = [Mock()]
            mock_msg2.content[0].annotations = [Mock()]
            mock_msg2.content[0].annotations[
                0
            ].type = "container_file_citation"
            mock_msg2.content[0].annotations[0].file_id = "file-output-456"
            mock_msg2.content[0].annotations[0].container_id = "container-456"
            mock_msg2.content[0].annotations[0].filename = "results.csv"

            mock_response.output = [mock_msg1, mock_msg2]

            # Test download
            downloaded_paths = await self.manager.download_generated_files(
                mock_response, temp_dir
            )

            assert len(downloaded_paths) == 2
            assert all(os.path.exists(path) for path in downloaded_paths)

            # Verify file contents
            chart_path = os.path.join(temp_dir, "chart.png")
            results_path = os.path.join(temp_dir, "results.csv")

            assert chart_path in downloaded_paths
            assert results_path in downloaded_paths

            with open(chart_path, "rb") as f:
                assert f.read() == b"fake image data"

            with open(results_path, "rb") as f:
                assert f.read() == b"name,value\ntest,123"

    @pytest.mark.asyncio
    async def test_download_generated_files_no_filename(self):
        """Test downloading files when filename is not provided."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Mock file info without filename
            mock_file_info = Mock()
            mock_file_info.filename = None

            mock_content = Mock()
            mock_content.read.return_value = b"test data"

            self.mock_client.files.retrieve.return_value = mock_file_info
            self.mock_client.files.content.return_value = mock_content

            # Create mock response with annotation but no filename
            mock_response = Mock()
            mock_msg = Mock()
            mock_msg.type = "message"
            mock_msg.content = [Mock()]
            mock_msg.content[0].annotations = [Mock()]
            mock_msg.content[0].annotations[0].type = "container_file_citation"
            mock_msg.content[0].annotations[0].file_id = "file-output-123"
            mock_msg.content[0].annotations[0].container_id = "container-123"
            mock_msg.content[0].annotations[0].filename = None

            mock_response.output = [mock_msg]

            # Test download
            downloaded_paths = await self.manager.download_generated_files(
                mock_response, temp_dir
            )

            assert len(downloaded_paths) == 1
            # Should use file_id as filename when no other filename is available
            assert "file-output-123" in downloaded_paths[0]

    @pytest.mark.asyncio
    async def test_download_generated_files_no_annotations(self):
        """Test downloading files when no annotations are present."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create mock response with no annotations
            mock_response = Mock()
            mock_msg = Mock()
            mock_msg.type = "message"
            mock_msg.content = [Mock()]
            mock_msg.content[0].annotations = []  # No annotations

            mock_response.output = [mock_msg]

            # Test download
            downloaded_paths = await self.manager.download_generated_files(
                mock_response, temp_dir
            )

            # Should return empty list when no annotations are found
            assert len(downloaded_paths) == 0

    @pytest.mark.asyncio
    async def test_download_generated_files_no_files(self):
        """Test downloading when no files are present."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create mock response with no output
            mock_response = Mock()
            mock_response.output = []

            # Test download
            downloaded_paths = await self.manager.download_generated_files(
                mock_response, temp_dir
            )

            assert len(downloaded_paths) == 0

    @pytest.mark.asyncio
    async def test_cleanup_uploaded_files(self):
        """Test cleanup of uploaded files."""
        # Set up some uploaded file IDs
        self.manager.uploaded_file_ids = ["file-123", "file-456", "file-789"]

        await self.manager.cleanup_uploaded_files()

        # Verify all files were deleted
        assert self.mock_client.files.delete.call_count == 3
        delete_calls = [
            call[0][0] for call in self.mock_client.files.delete.call_args_list
        ]
        assert "file-123" in delete_calls
        assert "file-456" in delete_calls
        assert "file-789" in delete_calls

        # Verify uploaded_file_ids was cleared
        assert self.manager.uploaded_file_ids == []

    @pytest.mark.asyncio
    async def test_cleanup_uploaded_files_with_errors(self):
        """Test cleanup handling deletion errors gracefully."""
        self.manager.uploaded_file_ids = ["file-123", "file-456"]

        # Mock deletion failure for one file
        def delete_side_effect(file_id):
            if file_id == "file-123":
                raise Exception("Deletion failed")
            return Mock()

        self.mock_client.files.delete.side_effect = delete_side_effect

        # Should not raise exception, just log warnings
        await self.manager.cleanup_uploaded_files()

        assert self.mock_client.files.delete.call_count == 2
        assert self.manager.uploaded_file_ids == []

    def test_validate_files_for_upload_valid_files(self):
        """Test validation of valid files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create valid test files
            valid_files = []
            for filename in [
                "test.py",
                "data.csv",
                "config.json",
                "readme.md",
            ]:
                file_path = os.path.join(temp_dir, filename)
                with open(file_path, "w") as f:
                    f.write("test content")
                valid_files.append(file_path)

            errors = self.manager.validate_files_for_upload(valid_files)
            assert errors == []

    def test_validate_files_for_upload_missing_files(self):
        """Test validation with missing files."""
        missing_files = [
            "/path/that/does/not/exist.py",
            "/another/missing/file.csv",
        ]

        errors = self.manager.validate_files_for_upload(missing_files)

        assert len(errors) == 2
        assert any("File not found" in error for error in errors)

    def test_validate_files_for_upload_large_files(self):
        """Test validation with files that are too large."""
        with tempfile.TemporaryDirectory() as temp_dir:
            large_file = os.path.join(temp_dir, "large.txt")

            # Create a file larger than 100MB (mock by patching os.path.getsize)
            with open(large_file, "w") as f:
                f.write("test")

            # Patch os.path.getsize in the code_interpreter module specifically
            with patch(
                "ostruct.cli.code_interpreter.os.path.getsize",
                return_value=150 * 1024 * 1024,
            ):  # 150MB
                errors = self.manager.validate_files_for_upload([large_file])

                assert len(errors) == 1
                assert "File too large" in errors[0]
                assert "150.0MB > 100MB" in errors[0]

    def test_get_container_limits_info(self):
        """Test getting container limits information."""
        limits = self.manager.get_container_limits_info()

        expected_keys = {
            "max_runtime_minutes",
            "idle_timeout_minutes",
            "max_file_size_mb",
            "supported_languages",
            "note",
        }

        assert set(limits.keys()) == expected_keys
        assert limits["max_runtime_minutes"] == 20
        assert limits["idle_timeout_minutes"] == 2
        assert limits["max_file_size_mb"] == 100
        assert limits["supported_languages"] == ["python"]
        assert "Container expires" in limits["note"]


class TestCodeInterpreterIntegration:
    """Test Code Interpreter integration scenarios."""

    def setup_method(self):
        """Set up test fixtures."""
        self.mock_client = AsyncMock()
        self.manager = CodeInterpreterManager(self.mock_client)

    @pytest.mark.asyncio
    async def test_full_workflow_upload_and_cleanup(self):
        """Test complete workflow: upload files, build config, cleanup."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create test files
            test_files = []
            for i in range(3):
                file_path = os.path.join(temp_dir, f"test{i}.py")
                with open(file_path, "w") as f:
                    f.write(f'print("test {i}")')
                test_files.append(file_path)

            # Mock upload responses
            mock_files = [Mock(id=f"file-{i}") for i in range(3)]
            self.mock_client.files.create.side_effect = mock_files

            # Upload files
            file_ids = await self.manager.upload_files_for_code_interpreter(
                test_files
            )
            assert len(file_ids) == 3

            # Build tool config
            tool_config = self.manager.build_tool_config(file_ids)
            assert tool_config["type"] == "code_interpreter"
            assert tool_config["container"]["file_ids"] == file_ids

            # Cleanup
            await self.manager.cleanup_uploaded_files()
            assert self.mock_client.files.delete.call_count == 3
            assert self.manager.uploaded_file_ids == []

    @pytest.mark.asyncio
    async def test_error_recovery_during_upload(self):
        """Test error recovery when upload fails partway through."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create test files
            test_files = []
            for i in range(3):
                file_path = os.path.join(temp_dir, f"test{i}.py")
                with open(file_path, "w") as f:
                    f.write(f'print("test {i}")')
                test_files.append(file_path)

            # Mock partial success then failure
            mock_file1 = Mock(id="file-1")
            self.mock_client.files.create.side_effect = [
                mock_file1,  # First upload succeeds
                Exception("Upload failed"),  # Second upload fails
            ]

            # Should cleanup successfully uploaded files on error
            with pytest.raises(Exception, match="Upload failed"):
                await self.manager.upload_files_for_code_interpreter(
                    test_files
                )

            # Verify cleanup was called for the successful upload
            self.mock_client.files.delete.assert_called_once_with("file-1")

    def test_file_validation_edge_cases(self):
        """Test file validation with various edge cases."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create files with different extensions
            test_cases = [
                ("supported.py", True),
                ("data.csv", True),
                ("config.json", True),
                ("readme.md", True),
                ("script.js", True),
                ("query.sql", True),
                ("unsupported.exe", False),  # Should warn but not error
                ("binary.bin", False),  # Should warn but not error
            ]

            files_to_validate = []
            for filename, _ in test_cases:
                file_path = os.path.join(temp_dir, filename)
                with open(file_path, "w") as f:
                    f.write("test content")
                files_to_validate.append(file_path)

            errors = self.manager.validate_files_for_upload(files_to_validate)

            # Should not have errors for any existing files
            # (warnings are logged, not returned as errors)
            assert errors == []


class TestCodeInterpreterPerformance:
    """Test Code Interpreter performance considerations."""

    def setup_method(self):
        """Set up test fixtures."""
        self.mock_client = AsyncMock()
        self.manager = CodeInterpreterManager(self.mock_client)

    @pytest.mark.asyncio
    async def test_batch_file_upload_efficiency(self):
        """Test efficient handling of multiple file uploads."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create multiple test files
            test_files = []
            for i in range(10):
                file_path = os.path.join(temp_dir, f"batch_test_{i}.py")
                with open(file_path, "w") as f:
                    f.write(f'# Test file {i}\nprint("batch test {i}")')
                test_files.append(file_path)

            # Mock upload responses
            mock_files = [Mock(id=f"file-batch-{i}") for i in range(10)]
            self.mock_client.files.create.side_effect = mock_files

            # Upload all files
            file_ids = await self.manager.upload_files_for_code_interpreter(
                test_files
            )

            assert len(file_ids) == 10
            assert self.mock_client.files.create.call_count == 10
            assert len(self.manager.uploaded_file_ids) == 10

    def test_memory_efficient_validation(self):
        """Test that file validation doesn't load entire file contents."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create a reasonably sized file
            large_file = os.path.join(temp_dir, "large_data.csv")
            with open(large_file, "w") as f:
                # Write some data but not actually huge
                for i in range(1000):
                    f.write(f"row_{i},value_{i},data_{i}\n")

            # Validation should work without loading full content
            errors = self.manager.validate_files_for_upload([large_file])
            assert errors == []


class TestCodeInterpreterSecurity:
    """Test Code Interpreter security considerations."""

    def setup_method(self):
        """Set up test fixtures."""
        self.mock_client = AsyncMock()
        self.manager = CodeInterpreterManager(self.mock_client)

    def test_file_path_validation(self):
        """Test validation of file paths for security."""
        # Test various file paths
        test_paths = [
            "/tmp/safe_file.py",
            "./relative_file.csv",
            "../parent_dir/file.json",
            "/etc/passwd",  # System file
            "normal_file.txt",
        ]

        # All paths should be validated for existence, not content
        # (Security is handled by OpenAI's Code Interpreter environment)
        errors = self.manager.validate_files_for_upload(test_paths)

        # All should fail with "File not found" since they don't exist
        assert len(errors) == len(test_paths)
        assert all("File not found" in error for error in errors)

    def test_container_limits_awareness(self):
        """Test awareness of Code Interpreter container limits."""
        limits = self.manager.get_container_limits_info()

        # Verify security-relevant limits are documented
        assert (
            limits["max_runtime_minutes"] <= 20
        )  # Reasonable execution time limit
        assert limits["max_file_size_mb"] <= 100  # Reasonable file size limit
        assert "python" in limits["supported_languages"]  # Known safe language
        assert (
            "expires" in limits["note"].lower()
        )  # Session expiration for security
