# CLI Reference

`ostruct` is a command-line tool for generating structured output from OpenAI models with advanced multi-tool integration. It processes text and files using OpenAI's models while ensuring output follows a specific JSON schema.

## New Features Overview

The enhanced CLI includes:

- **Code Interpreter**: Upload and analyze data files, execute Python code, generate visualizations
- **File Search**: Vector-based document search and retrieval from uploaded files
- **MCP Servers**: Connect to Model Context Protocol servers for extended functionality
- **Explicit File Routing**: Route different files to specific tools for optimized processing
- **Configuration System**: YAML-based configuration with environment variable support
- **Progress Reporting**: Real-time progress updates with clear, user-friendly messaging

## Basic Usage

```bash
ostruct run TEMPLATE_FILE SCHEMA_FILE [OPTIONS]
```

## Required Arguments

- `TEMPLATE_FILE`: Path to Jinja2 template file (typically with `.j2` extension)
- `SCHEMA_FILE`: JSON Schema file that defines the structure of the output

## File Routing Options

### üìÑ Template Files (Available in template context only)

```bash
# Auto-naming: -ft config.yaml ‚Üí config_yaml variable
-ft, --file-for-template PATH

# Equals syntax: -ft name=path ‚Üí name variable
-ft, --file-for-template NAME=PATH

# Two-argument alias: --fta name path ‚Üí name variable (with tab completion)
--fta, --file-for-template-alias NAME PATH

# Directories
-dt, --dir-for-template DIR           Map directory for template access
```

### üíª Code Interpreter Files (Uploaded for execution + available in template)

```bash
# Auto-naming: -fc data.csv ‚Üí data_csv variable
-fc, --file-for-code-interpreter PATH

# Equals syntax: -fc dataset=data.csv ‚Üí dataset variable
-fc, --file-for-code-interpreter NAME=PATH

# Two-argument alias: --fca dataset data.csv ‚Üí dataset variable (with tab completion)
--fca, --file-for-code-interpreter-alias NAME PATH

# Directories
-dc, --dir-for-code-interpreter DIR      Upload directories for analysis
```

### üîç File Search Files (Uploaded to vector store + available in template)

```bash
# Auto-naming: -fs docs.pdf ‚Üí docs_pdf variable
-fs, --file-for-search PATH

# Equals syntax: -fs manual=docs.pdf ‚Üí manual variable
-fs, --file-for-search NAME=PATH

# Two-argument alias: --fsa manual docs.pdf ‚Üí manual variable (with tab completion)
--fsa, --file-for-search-alias NAME PATH

# Directories
-ds, --dir-for-search DIR                Upload directories for search
```

### Legacy Compatibility
Traditional flags continue to work exactly as before:

```bash
-f, --file NAME=FILE                     Map file to template variable
-d, --dir NAME=DIR                       Map directory to template variable
-p, --pattern NAME=PATTERN               Map glob pattern to template variable
```

### Advanced File Routing
Route files to multiple tools simultaneously:

```bash
--file-for TOOLS:FILES                   Route specific files to multiple tools
                                         Example: --file-for code-interpreter,file-search:data.json
```

## Tool Integration Options

### MCP Server Integration
Connect to Model Context Protocol servers:

```bash
--mcp-server [LABEL@]URL                 Connect to MCP server
                                         Example: --mcp-server deepwiki@https://mcp.deepwiki.com/sse
```

### Configuration
```bash
--config PATH                            Configuration file path (default: ostruct.yaml)
```

## Model and API Options

### Model Selection
```bash
-m, --model MODEL                        OpenAI model to use (default from config or gpt-4o)
```

Supported models:
- `gpt-4o` (128k context window)
- `o1` (200k context window)
- `o3-mini` (200k context window)

### Model Parameters
```bash
--temperature FLOAT                      Sampling temperature (0.0-2.0)
--max-output-tokens INT                  Maximum tokens in output
--top-p FLOAT                           Top-p sampling parameter
--frequency-penalty FLOAT               Frequency penalty parameter
--presence-penalty FLOAT                Presence penalty parameter
```

Note: Parameter support varies by model. Unsupported parameters will cause validation errors.

### API Configuration
```bash
--timeout FLOAT                         API timeout in seconds (default: 60.0)
--api-key KEY                           OpenAI API key (or use OPENAI_API_KEY env var)
```

## Variable and Input Options

### Simple Variables
```bash
-V, --var NAME=VALUE                     Pass simple variables to template
--json-var NAME=JSON                     Pass JSON-structured variables to template
```

### Directory Processing
```bash
--dir-recursive                          Process directories recursively
--dir-ext EXTENSIONS                     Comma-separated file extensions to include
--base-dir PATH                          Base directory for resolving relative paths
```

### Security Options
```bash
--allowed-dir PATH                       Additional allowed directory
--allowed-dir-file PATH                  File containing allowed directories list
```

## System Prompt Options

```bash
--sys-prompt TEXT                        System prompt string directly
--sys-file PATH                          Path to system prompt file
--ignore-task-sysprompt                  Ignore system prompt from template frontmatter
```

### Precedence Order
1. Command-line options (`--sys-prompt` takes precedence over `--sys-file`)
2. Template frontmatter (YAML header in template file)
3. Default system prompt

## Output Options

```bash
-o, --output-file PATH                   Write output to file instead of stdout
--show-model-schema                      Display generated Pydantic model schema
```

## Progress and Debug Options

### Progress Reporting
```bash
--progress-level {none,basic,detailed}   Set progress reporting level (default: basic)
--no-progress                           Disable progress indicators
```

### Debug Options
```bash
--debug-validation                       Show detailed schema validation debugging
--debug-openai-stream                   Enable low-level OpenAI streaming debug
--verbose                               Enable verbose output and detailed logging
--dry-run                               Preview operation without API calls
```

## Examples

### Basic Text Extraction
```bash
# Simple stdin processing
echo "John is a 30-year-old engineer" | ostruct run extract.j2 person_schema.json

# File processing with auto-naming
ostruct run analysis.j2 schema.json -ft config.yaml -fc data.csv
```

### Multi-Tool Data Analysis with Different Syntax Options
```bash
# Mix of auto-naming, equals, and alias syntax
ostruct run analysis.j2 analysis_schema.json \
  -fc sales_data.csv \
  -fc customer_data=customers.json \
  --fsa market_reports market_reports.pdf \
  --fta app_config config.yaml

# Auto-naming only (fastest for one-off usage)
ostruct run quick_analysis.j2 schema.json \
  -fc data.csv \
  -fs docs.pdf \
  -ft settings.yaml

# Alias syntax only (best for reusable templates)
ostruct run reusable_template.j2 schema.json \
  --fca dataset data.csv \
  --fsa manual docs.pdf \
  --fta config settings.yaml
```

### Code Review with Documentation Context
```bash
# Code analysis with stable variable names for reusable templates
ostruct run code_review.j2 review_schema.json \
  --fca source_code source_code/ \
  --fsa documentation docs/ \
  --fta eslint_config .eslintrc.json

# Mixed syntax example
ostruct run code_review.j2 review_schema.json \
  -fc source_code/ \
  -fs docs/ \
  -ft lint_rules=.eslintrc.json
```

### MCP Server Integration
```bash
# Connect to external data sources
ostruct run market_analysis.j2 analysis_schema.json \
  -fc local_data.csv \
  --mcp-server market@https://api.market.com/mcp \
  --mcp-server news@https://news.api.com/mcp
```

### Configuration-Driven Workflow
```bash
# Use persistent configuration
ostruct --config production.yaml run template.j2 schema.json \
  -fc datasets/ \
  -fs documentation/
```

### Legacy Compatibility Examples
All existing patterns continue to work:

```bash
# Traditional file mapping (unchanged)
ostruct run template.j2 schema.json -f data=input.txt -d source=./src

# Pattern matching (unchanged)
ostruct run template.j2 schema.json -p "*.py" source_files

# Variable passing (unchanged)
ostruct run template.j2 schema.json -V env=prod -V debug=false
```

## Template Files

Template files use Jinja2 syntax with `.j2` extension. Templates can include YAML frontmatter:

```jinja
---
system_prompt: You are an expert data analyst
---
Analyze this data: {{ data.content }}

{% if code_interpreter_files %}
The following files are available for Python execution:
{% for file in code_interpreter_files %}
- {{ file.name }}: {{ file.description }}
{% endfor %}
{% endif %}

{% if file_search_results %}
Relevant documentation found:
{% for result in file_search_results %}
- {{ result.title }}: {{ result.summary }}
{% endfor %}
{% endif %}
```

### Template Variables

#### File Access Variables
- `stdin`: Content from standard input
- `<name>.content`: Content of files mapped with `-ft`, `-f`
- `<name>.*`: Directory listings from `-dt`, `-d`

#### Tool-Specific Variables
- `code_interpreter_files`: List of files uploaded to Code Interpreter
- `file_search_results`: Results from File Search operations
- `mcp_context`: Context from connected MCP servers

#### System Variables
- `current_model`: The model being used
- `timestamp`: Current timestamp
- `config`: Configuration values (if applicable)

## Configuration System

### Configuration File Format

Create `ostruct.yaml` in your project directory or specify with `--config`:

```yaml
# Model settings
models:
  default: gpt-4o

# Tool-specific configuration
tools:
  code_interpreter:
    auto_download: true
    output_directory: "./output"

  file_search:
    max_results: 10

# MCP server shortcuts
mcp:
  stripe: "https://mcp.stripe.com"
  custom: "https://my-server.com/mcp"

# Operation settings
operation:
  timeout_minutes: 60
  retry_attempts: 3
  require_approval: never  # Options: never, always, expensive

# Cost and safety limits
limits:
  max_cost_per_run: 10.00
  warn_expensive_operations: true
```

### Environment Variable Support

Configuration supports environment variable overrides:

```bash
# API keys and secrets
export OPENAI_API_KEY="your-key"

# MCP server URLs
export MCP_STRIPE_URL="https://custom.stripe.com"
export MCP_CUSTOM_URL="https://my-mcp-server.com"
```

## Advanced Usage Patterns

### Parallel Processing
```bash
# Process multiple datasets simultaneously
ostruct run analysis.j2 schema.json \
  -fc dataset1.csv \
  -fc dataset2.csv \
  -fc dataset3.csv \
  -fs documentation/
```

### Multi-Environment Configuration
```bash
# Development
ostruct --config dev.yaml run template.j2 schema.json -fc dev_data/

# Production
ostruct --config prod.yaml run template.j2 schema.json -fc prod_data/
```

### CI/CD Integration
```bash
# Automated analysis in CI/CD
ostruct run ci_analysis.j2 ci_schema.json \
  -fc test_results/ \
  -fc coverage_data/ \
  -fs documentation/ \
  -ft ci_config.yaml \
  --config production.yaml \
  --progress-level none
```

## Error Handling and Troubleshooting

### Common Error Patterns

**File Routing Issues**:
```bash
# Problem: File not found or access denied
# Solution: Check file paths and use --allowed-dir if needed
ostruct run template.j2 schema.json -fc /path/to/data.csv --allowed-dir /path/to
```

**Token Limit Exceeded**:
```bash
# Problem: Input too large for model context
# Solution: Use explicit routing to optimize file usage
ostruct run template.j2 schema.json -ft large_config.json -fc analysis_data.csv
```

**Tool Access Issues**:
```bash
# Problem: Code Interpreter or File Search not available
# Solution: Verify API key permissions and model capabilities
ostruct run template.j2 schema.json --model gpt-4o -fc data.csv
```

### Debug Strategies

1. **Dry Run First**: Use `--dry-run` to validate setup
2. **Check Configuration**: Verify `ostruct.yaml` syntax
3. **Test File Access**: Ensure files are accessible and properly routed
4. **Monitor Progress**: Use `--progress-level detailed` for visibility
5. **Check Logs**: Review logs in `~/.ostruct/logs/` for detailed errors

## Environment Variables

```bash
# Required
OPENAI_API_KEY=your-api-key

# Optional API configuration
OPENAI_API_BASE=custom-base-url
OPENAI_API_VERSION=api-version
OPENAI_API_TYPE=azure

# MCP server URLs
MCP_<NAME>_URL=server-url

# Feature toggles
OSTRUCT_DISABLE_UPDATE_CHECKS=1
```

## Security Considerations

### File Access Control
- Default access limited to current working directory
- Use `--allowed-dir` for additional directories
- Validate file permissions before processing
- Avoid exposing sensitive data in templates

### API Key Management
- Store API keys in environment variables
- Use secret management in CI/CD environments
- Rotate keys regularly
- Monitor API usage and costs

### Cost Controls
- Set `max_cost_per_run` in configuration
- Monitor token usage with `--dry-run`
- Use `warn_expensive_operations` flag
- Implement budget alerts in automation

## Migration from Legacy CLI

### Step-by-Step Migration

1. **Test Compatibility**: Existing commands should work unchanged
2. **Add Explicit Routing**: Convert `-f` to `-ft`, `-fc`, or `-fs` based on usage
3. **Create Configuration**: Add `ostruct.yaml` for persistent settings
4. **Enable Progress Reporting**: Use `--progress-level detailed` for better visibility
5. **Optimize Performance**: Use tool-specific routing for better resource utilization

### Migration Examples

```bash
# Before (legacy)
ostruct run template.j2 schema.json -f data=input.csv -d docs=./documentation

# After (enhanced)
ostruct run template.j2 schema.json -fc input.csv -fs ./documentation
```

For complete migration guidance, see the migration documentation (coming soon).

## Quick Reference Commands

```bash
# Show help for file routing
ostruct quick-ref

# Check configuration
ostruct --config my-config.yaml run --dry-run template.j2 schema.json

# Test file access
ostruct run template.j2 schema.json -ft test.txt --dry-run

# Monitor costs
ostruct run template.j2 schema.json -fc data.csv --dry-run --verbose
```

## Best Practices

1. **Use Explicit Routing**: Be specific about how files are used (`-ft`, `-fc`, `-fs`)
2. **Create Configuration Files**: Use `ostruct.yaml` for consistent behavior
3. **Test with Dry Run**: Validate setup before making API calls
4. **Monitor Costs**: Set limits and use cost estimation
5. **Secure File Access**: Use `--allowed-dir` appropriately
6. **Document Workflows**: Keep examples and patterns documented for team use
